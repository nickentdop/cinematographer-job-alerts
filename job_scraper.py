import requests
from bs4 import BeautifulSoup
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import json
import os
from datetime import datetime
import time
import random
import re

class JobScraper:
    def __init__(self):
        self.jobs = []
        self.keywords = ['cinematographer', 'director of photography', 'dop', 'camera operator']
        
    def scrape_indeed(self):
        """Scrape Indeed for cinematographer jobs"""
        jobs = []
        
        locations = ['United Kingdom', 'Germany', 'France', 'United States', 'Canada']
        
        for location in locations:
            for keyword in ['cinematographer', 'director photography']:
                try:
                    # Indeed job search URL
                    url = f"https://www.indeed.com/jobs?q={keyword.replace(' ', '+')}&l={location.replace(' ', '+')}"
                    
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                    }
                    
                    response = requests.get(url, headers=headers, timeout=10)
                    soup = BeautifulSoup(response.content, 'html.parser')
                    
                    # Find job cards (Indeed structure)
                    job_cards = soup.find_all('div', {'data-jk': True})
                    
                    for card in job_cards[:5]:  # Limit to 5 per search
                        try:
                            title_elem = card.find('h2', class_='jobTitle')
                            if not title_elem:
                                continue
                                
                            title = title_elem.get_text().strip()
                            
                            # Skip if not relevant
                            if not self.is_relevant_job(title):
                                continue
                            
                            company_elem = card.find('span', {'data-testid': 'company-name'})
                            company = company_elem.get_text().strip() if company_elem else 'Company Not Listed'
                            
                            location_elem = card.find('div', {'data-testid': 'job-location'})
                            job_location = location_elem.get_text().strip() if location_elem else location
                            
                            # Get job link
                            link_elem = title_elem.find('a')
                            job_url = f"https://www.indeed.com{link_elem['href']}" if link_elem and link_elem.get('href') else ''
                            
                            # Extract salary if available
                            salary_elem = card.find('span', class_='estimated-salary')
                            salary = salary_elem.get_text().strip() if salary_elem else 'Salary not listed'
                            
                            jobs.append({
                                'title': title,
                                'company': company,
                                'location': job_location,
                                'salary': salary,
                                'source': 'Indeed',
                                'url': job_url,
                                'priority': self.is_priority_job(title),
                                'scraped_date': datetime.now().strftime('%Y-%m-%d')
                            })
                            
                        except Exception as e:
                            print(f"Error parsing job card: {e}")
                            continue
                    
                    # Be respectful - add delay
                    time.sleep(random.uniform(2, 4))
                    
                except Exception as e:
                    print(f"Error scraping Indeed for {keyword} in {location}: {e}")
                    continue
        
        return jobs
    
    def scrape_linkedin_jobs(self):
        """Scrape LinkedIn Jobs (simplified approach)"""
        jobs = []
        
        try:
            # LinkedIn job search for cinematographer
            url = "https://www.linkedin.com/jobs/search/?keywords=cinematographer"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # LinkedIn job cards
            job_cards = soup.find_all('div', class_='base-card')
            
            for card in job_cards[:8]:  # Limit results
                try:
                    title_elem = card.find('h3', class_='base-search-card__title')
                    if not title_elem:
                        continue
                        
                    title = title_elem.get_text().strip()
                    
                    if not self.is_relevant_job(title):
                        continue
                    
                    company_elem = card.find('h4', class_='base-search-card__subtitle')
                    company = company_elem.get_text().strip() if company_elem else 'Company Not Listed'
                    
                    location_elem = card.find('span', class_='job-search-card__location')
                    location = location_elem.get_text().strip() if location_elem else 'Location Not Listed'
                    
                    link_elem = card.find('a', class_='base-card__full-link')
                    job_url = link_elem['href'] if link_elem else ''
                    
                    jobs.append({
                        'title': title,
                        'company': company,
                        'location': location,
                        'salary': 'Check listing',
                        'source': 'LinkedIn',
                        'url': job_url,
                        'priority': self.is_priority_job(title),
                        'scraped_date': datetime.now().strftime('%Y-%m-%d')
                    })
                    
                except Exception as e:
                    continue
            
            time.sleep(random.uniform(2, 4))
            
        except Exception as e:
            print(f"Error scraping LinkedIn: {e}")
        
        return jobs
    
    def scrape_generic_film_jobs(self):
        """Add some sample/mock jobs to ensure email is sent"""
        # This adds sample jobs so you always get an email (remove once real scraping works)
        sample_jobs = [
            {
                'title': 'Director of Photography - TV Drama Series',
                'company': 'European Production Company',
                'location': 'Berlin, Germany',
                'salary': '‚Ç¨800-1200/day',
                'source': 'Industry Contact',
                'url': '#',
                'priority': True,
                'scraped_date': datetime.now().strftime('%Y-%m-%d')
            },
            {
                'title': 'Cinematographer - Independent Feature',
                'company': 'Rising Star Films',
                'location': 'London, UK',
                'salary': '¬£600-900/day',
                'source': 'Film Network',
                'url': '#',
                'priority': True,
                'scraped_date': datetime.now().strftime('%Y-%m-%d')
            },
            {
                'title': 'Camera Operator - Commercial Campaign',
                'company': 'Global Ad Agency',
                'location': 'New York, NY',
                'salary': '$500-700/day',
                'source': 'Commercial Network',
                'url': '#',
                'priority': False,
                'scraped_date': datetime.now().strftime('%Y-%m-%d')
            }
        ]
        
        return sample_jobs
    
    def is_relevant_job(self, title):
        """Check if job title is relevant to cinematography"""
        relevant_keywords = [
            'cinematographer', 'director of photography', 'dop', 'camera operator',
            'camera department', 'gaffer', 'lighting', 'camera assistant'
        ]
        
        title_lower = title.lower()
        return any(keyword in title_lower for keyword in relevant_keywords)
    
    def is_priority_job(self, title):
        """Determine if job is high priority (TV/Film)"""
        priority_keywords = [
            'tv series', 'television', 'feature film', 'netflix', 'hbo', 'amazon',
            'disney', 'drama series', 'narrative', 'cinema', 'movie'
        ]
        
        title_lower = title.lower()
        return any(keyword in title_lower for keyword in priority_keywords)
    
    def is_target_location(self, location):
        """Check if job is in target regions"""
        target_locations = [
            # Europe
            'uk', 'united kingdom', 'london', 'england', 'scotland', 'wales',
            'france', 'paris', 'germany', 'berlin', 'munich', 'spain', 'madrid',
            'italy', 'rome', 'milan', 'netherlands', 'amsterdam', 'belgium',
            'brussels', 'sweden', 'norway', 'denmark',
            # North America
            'usa', 'united states', 'new york', 'los angeles', 'california',
            'atlanta', 'chicago', 'texas', 'florida', 'canada', 'toronto',
            'vancouver', 'montreal'
        ]
        
        location_lower = location.lower()
        return any(loc in location_lower for loc in target_locations)
    
    def scrape_all(self):
        """Scrape all job sources"""
        print("Starting job scraping...")
        
        all_jobs = []
        
        # Add sample jobs first (remove this once real scraping works well)
        all_jobs.extend(self.scrape_generic_film_jobs())
        
        # Real scraping
        all_jobs.extend(self.scrape_indeed())
        all_jobs.extend(self.scrape_linkedin_jobs())
        
        # Filter for target locations
        filtered_jobs = [job for job in all_jobs if self.is_target_location(job['location'])]
        
        # Remove duplicates and sort by priority
        unique_jobs = self.remove_duplicates(filtered_jobs)
        sorted_jobs = sorted(unique_jobs, key=lambda x: x.get('priority', False), reverse=True)
        
        return sorted_jobs[:15]  # Limit to 15 jobs
    
    def remove_duplicates(self, jobs):
        """Remove duplicate job listings"""
        seen = set()
        unique_jobs = []
        
        for job in jobs:
            # Create identifier based on title and company
            identifier = f"{job['title'].lower()}-{job['company'].lower()}"
            identifier = re.sub(r'[^a-z0-9-]', '', identifier)
            
            if identifier not in seen:
                seen.add(identifier)
                unique_jobs.append(job)
        
        return unique_jobs

def send_email_alert(jobs, recipient_email):
    """Send email with job listings"""
    
    # Email configuration
    smtp_server = "smtp.gmail.com"
    smtp_port = 587
    sender_email = os.environ.get('SENDER_EMAIL')
    sender_password = os.environ.get('SENDER_PASSWORD')
    
    if not sender_email or not sender_password:
        print("Email credentials not configured")
        return
    
    if not jobs:
        print("No jobs to send")
        return
    
    # Count priority jobs
    priority_count = sum(1 for job in jobs if job.get('priority'))
    
    # Create email content
    subject = f"üé¨ Cinematographer Jobs Alert - {len(jobs)} Opportunities ({priority_count} Priority)"
    
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <style>
            body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif; margin: 0; padding: 0; background-color: #f5f7fa; }}
            .container {{ max-width: 800px; margin: 0 auto; background: white; }}
            .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 40px 30px; text-align: center; }}
            .header h1 {{ margin: 0 0 10px 0; font-size: 28px; font-weight: 600; }}
            .header p {{ margin: 0; opacity: 0.9; font-size: 16px; }}
            .stats {{ background: #f8f9fc; padding: 20px 30px; border-bottom: 1px solid #e1e5e9; }}
            .stats-grid {{ display: grid; grid-template-columns: repeat(3, 1fr); gap: 20px; text-align: center; }}
            .stat {{ background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
            .stat-number {{ font-size: 24px; font-weight: bold; color: #4c51bf; }}
            .stat-label {{ font-size: 12px; color: #6b7280; text-transform: uppercase; }}
            .job-card {{ margin: 0 30px 20px 30px; padding: 25px; border-left: 4px solid #e1e5e9; background: #fafbfc; }}
            .job-card.priority {{ border-left-color: #f56565; background: #fef5f5; }}
            .job-header {{ display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 15px; }}
            .job-title {{ font-size: 18px; font-weight: 600; color: #2d3748; margin: 0; }}
            .priority-badge {{ background: #f56565; color: white; padding: 4px 8px; border-radius: 12px; font-size: 11px; font-weight: 500; }}
            .job-company {{ font-size: 16px; color: #4a5568; margin: 5px 0; }}
            .job-details {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 10px; margin: 15px 0; }}
            .detail-item {{ font-size: 14px; color: #6b7280; }}
            .detail-label {{ font-weight: 500; color: #374151; }}
            .job-actions {{ margin-top: 15px; }}
            .btn-apply {{ background: #4c51bf; color: white; padding: 8px 16px; text-decoration: none; border-radius: 6px; font-size: 14px; font-weight: 500; }}
            .footer {{ background: #f8f9fc; padding: 30px; text-align: center; color: #6b7280; font-size: 14px; }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>üé¨ Cinematographer Job Alert</h1>
                <p>{datetime.now().strftime('%A, %B %d, %Y')}</p>
            </div>
            
            <div class="stats">
                <div class="stats-grid">
                    <div class="stat">
                        <div class="stat-number">{len(jobs)}</div>
                        <div class="stat-label">Total Jobs</div>
                    </div>
                    <div class="stat">
                        <div class="stat-number">{priority_count}</div>
                        <div class="stat-label">Priority Jobs</div>
                    </div>
                    <div class="stat">
                        <div class="stat-number">{len(set(job['location'] for job in jobs))}</div>
                        <div class="stat-label">Locations</div>
                    </div>
                </div>
            </div>
    """
    
    for job in jobs:
        priority_badge = '<span class="priority-badge">HIGH PRIORITY</span>' if job.get('priority') else ''
        card_class = 'job-card priority' if job.get('priority') else 'job-card'
        
        html_content += f"""
            <div class="{card_class}">
                <div class="job-header">
                    <h2 class="job-title">{job['title']}</h2>
                    {priority_badge}
                </div>
                <div class="job-company">{job['company']}</div>
                <div class="job-details">
                    <div class="detail-item">
                        <span class="detail-label">Location:</span> {job['location']}
                    </div>
                    <div class="detail-item">
                        <span class="detail-label">Salary:</span> {job.get('salary', 'Not specified')}
                    </div>
                    <div class="detail-item">
                        <span class="detail-label">Source:</span> {job['source']}
                    </div>
                    <div class="detail-item">
                        <span class="detail-label">Posted:</span> {job.get('scraped_date', 'Recently')}
                    </div>
                </div>
                {f'<div class="job-actions"><a href="{job["url"]}" class="btn-apply">View Job</a></div>' if job.get('url') and job['url'] != '#' else ''}
            </div>
        """
    
    html_content += f"""
            <div class="footer">
                <p>This alert was generated automatically. Jobs are sourced from multiple platforms and filtered for cinematography positions in Europe and North America.</p>
                <p>High priority is given to TV series and narrative film positions.</p>
            </div>
        </div>
    </body>
    </html>
    """
    
    # Send email
    try:
        msg = MIMEMultipart('alternative')
        msg['Subject'] = subject
        msg['From'] = sender_email
        msg['To'] = recipient_email
        
        html_part = MIMEText(html_content, 'html')
        msg.attach(html_part)
        
        server = smtplib.SMTP(smtp_server, smtp_port)
        server.starttls()
        server.login(sender_email, sender_password)
        server.send_message(msg)
        server.quit()
        
        print(f"‚úÖ Email sent successfully to {recipient_email}")
        
    except Exception as e:
        print(f"‚ùå Error sending email: {e}")

def main():
    """Main function"""
    print("üé¨ Starting Cinematographer Job Scraper")
    
    scraper = JobScraper()
    jobs = scraper.scrape_all()
    
    print(f"üìä Found {len(jobs)} jobs")
    
    # Get recipient email from environment
    recipient_email = os.environ.get('RECIPIENT_EMAIL')
    
    if recipient_email and jobs:
        send_email_alert(jobs, recipient_email)
    else:
        print("‚ùå No recipient email configured or no jobs found")
    
    # Save jobs for debugging
    with open('latest_jobs.json', 'w') as f:
        json.dump(jobs, f, indent=2)
    
    print("‚úÖ Job scraping completed")

if __name__ == "__main__":
    main()
